---
title: Released Chainer/CuPy v6.0.0
layout: post
categories: Announcement
author: Seiya Tokui
---

We have released Chainer and CuPy v6.0.0 today!
This is a major release that introduces several new features.
Full updates can be found in the release notes: [Chainer](https://github.com/chainer/chainer/releases/tag/v6.0.0), [CuPy](https://github.com/cupy/cupy/releases/tag/v6.0.0).

## ChainerX

The biggest update is the introduction of **ChainerX**.
It is a fast and portable ndarray engine with autograd support written in C++ with very thin Python wrapper.

We have released the beta version of ChainerX in v6.0.0b1 as we wrote in the [previous blog post](https://chainer.org/announcement/2018/12/03/chainerx.html).
Since then, we have been working on improving it in various aspects.
In particular, ChainerX in v6.0.0 expands the coverage of various features since v6.0.0b1.

- **More op coverage**.
  We have more and more Chainer functions that directly call ChainerX's low-overhead implementation.
  The effort is still on going at [the tracking issue](https://github.com/chainer/chainer/issues/6423) with [the spreadsheet of op-wise implementation status](https://docs.google.com/spreadsheets/d/1B4E78tw9Awgpcdn5G7zsQ8NVFYJdOoJlIQg42QxKNfU).
  We continue expanding the op coverage towards next v7 release.
  Contributions are always welcomed!
- **More Function coverage**.
  Most users will start using ChainerX through Chainer's existing interface (just by replacing NumPy/CuPy array with ChainerX array).
  When ChainerX does not have an implementation for an operation, Chainer automatically falls back to NumPy/CuPy-based implementation.
  It basically works without any fix for most functions, but sometimes not.
  We are fixing such bugs to enlarge the coverage of functions for ChainerX usage.
  The effort is accompanied with the introduction of new simplistic test fixtures for function tests (you can find [the tracking issue](https://github.com/chainer/chainer/issues/6071)).
  The current test coverage is over 40%.
  We hope the coverage will reach 100% in v7.
  Contributions are always welcomed here, too!
- **More example coverage**.
  Most examples now support ChainerX.
  By specifying ChainerX's device names (e.g. `native` for CPU and `cuda:0`, `cuda:1`, ... for GPU), examples run with ChainerX arrays.
  It also means that the coverage of ChainerX support in Chainer's features in general is expanding.

You can find the [previous blog post](https://chainer.org/announcement/2018/12/03/chainerx.html) for its background and overview,
 and [ChainerX Documentation](https://docs.chainer.org/en/v6.0.0/chainerx/index.html) for the installation guide, tutorial, and reference.


## Other updates

This release also includes many features other than ChainerX.
We list up notable updates as follows.

- **More mixed precision support**.
  Chainer v6 introduces _mixed precision mode_ and _dynamic loss scaling_ for better support of mixed precision training.
  Mixed precision mode is enabled by setting `CHAINER_DTYPE=mixed16` or `chainer.global_config.dtype = chainer.mixed16`.
  In this mode, Chainer automatically chooses either of `float16` or `float32` which is appropriate for performance and precision balance.
  Dynamic loss scaling, originated from [Apex](https://github.com/NVIDIA/apex), automatically adjusts the scaling coefficient of backprop to avoid underflow.
- **Device API**.
  We introduce a new device API for better interoperability between backends (including ChainerX).
  It unifies the way to specify a device and transfer data between devices.
  In particular, unified device specifier is introduced.
  It is based on ChainerX's device specifier of format `'backend:id'`, e.g. `'native:0'` and `'cuda:N'` (where `N` is the CUDA device id).
  For native (CPU), the id part can be omitted (like `'native'`).
  For conventional devices backed by NumPy-like modules, the name is like `@numpy`, `@cupy:N`, and `@intel64`.
  This notation can be used, e.g., in the `to_device` function.
  Note that the existing APIs related to devices (e.g. `to_cpu` and `to_gpu`) are still available.
- **__array_function__ in CuPy**.
  NumPy's `__array_function__` is an experimental feature for letting NumPy dispatch implementations of almost all functions for third-party duck arrays.
  CuPy now supports this interface.
  To use this feature, you need to get NumPy 1.16 and set `NUMPY_EXPERIMENTAL_ARRAY_FUNCTION=1` (it will hopefully be the default mode in NumPy 1.17).
  Then, many NumPy functions that CuPy supports will accept CuPy arrays and automatically call CuPy's implementation.

We recommend updating to the latest version of Chainer and CuPy.
You can find the upgrade guide [here](https://docs.chainer.org/en/latest/upgrade.html).
Updating Chainer should be done as usual with the command `pip install -U chainer`.
Note that ChainerX is not built by default; see the [installation guide of ChainerX](https://docs.chainer.org/en/v6.0.0/chainerx/install/index.html) for details.
CuPy can be updated with `pip` as well, but be careful to use the appropriate package name if you are using a wheel package (`cupy-cuda NN`).

Any feedback to the dev team would be welcomed and appreciated.
You can ask questions or leave comments at [gitter](https://gitter.im/chainer), [Slack](https://bit.ly/join-chainer-slack), [Google Groups](https://groups.google.com/forum/#!forum/chainer), and [StackOverflow](https://stackoverflow.com/questions/tagged/chainer).
